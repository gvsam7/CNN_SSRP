# CNN_SSRP
Data type – Aerial images from Google Maps are provided free of charge and, with an appropriate data capture tool, can have a spatial resolution of 0.6m per pixel. The temporal information is, however, very limited; we only have the year when a particular part of Google Maps was updated. This is a challenge especially when we want to analyse changes, progress, or simply a current state of green spaces.
Learning task – Image classification is the task of classifying what appears in the entire aerial image into one out of a set of predefined classes. We can define agriculture, water body and street trees as the classes. The challenge is some objects such as water body, road occupy only a small portion of the image.
Learning model – A deep neural network with four hidden layers and a large number of neurons in each layer is employed. The idea of having more layers is to extract more fine-grained features of the aerial images. In general, as the depth of the learning model is increased, the learning capacity of the model is increased. This though happens at the cost of the computational complexity and memory storage. Some other issues in classical deep learning and machine learning relate to its lack of human interpretability and well-calibrated prediction uncertainty.
Learning process – At the current stage of the project, based on a simple cost-benefit analysis, we have decided to pursue passive learning with deep neural networks to solve an image classification problem based on aerial photography. Considering the limited temporal information of Google Maps’ aerial images, we only split the images into two temporal segments, 2017 – 2019 and 2013 – 2014. To ensure high classification accuracy with manageable computational complexity and memory storage, we used a neural network architecture with 4 fully convolutional layers while avoiding any expensive dense layer. The difficulty with classifying water body is addressed by supplementing our learning model with water body annotations from the OpenStreetMap.
Future development - In the next iteration of our deep learning model, we will implement a model with trainable attention mechanisms. This allows the model to be able to focus on important parts of the image, thereby facilitating human interpretability.
